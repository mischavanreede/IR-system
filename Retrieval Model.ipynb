{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    '''A document object is a dictionary'''\n",
    "    # Constructer method\n",
    "    def __init__(self, **dictionary_entries):\n",
    "        '''Initiates Document object with values from dictionary'''\n",
    "        # [id, article_url, title, author, publised_date, contents, type, source]\n",
    "        self.__dict__.update(dictionary_entries)\n",
    "    \n",
    "    # Getters (Should update: https://docs.python.org/2/library/functions.html#property)\n",
    "    def id(self):\n",
    "        return self.id\n",
    "    def article_url(self):\n",
    "        return self.article_url\n",
    "    def title(self):\n",
    "        return self.title\n",
    "    def author(self):\n",
    "        return self.author\n",
    "    def published_date(self):\n",
    "        return self.published_date\n",
    "    def contents(self):\n",
    "        return self.contents\n",
    "    def type(self):\n",
    "        return self.type\n",
    "    def source(self):\n",
    "        return self.source\n",
    "    \n",
    "    # Method for printing the object\n",
    "    def __str__(self):\n",
    "        # TODO: implement printing function\n",
    "        return \"Document Identifier: \" + self.id()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentDataStore:\n",
    "    '''This class is used to house all the document data'''\n",
    "    #https://www.youtube.com/watch?v=YBz3ERXQw_M\n",
    "    \n",
    "    def __init__(self, id_document_tuples):\n",
    "        '''Expects a list of: [{id, document_object},...]'''\n",
    "        self.id_document_tuples = id_document_tuples\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409428it [02:22, 4631.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n",
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n",
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n",
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410363it [02:22, 4403.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n",
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n",
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "588968it [07:45, 3896.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n",
      "ERROR: In extractDocumentDate()\n",
      "ERROR:  <class 'ValueError'>\n",
      "Caused by value: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "595037it [07:47, 1273.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN: 'pip install jsonlines' on: ModuleNotFoundError: No module named 'jsonlines'\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# RUN: 'pip install whoosh' on: ModuleNotFoundError: No module named 'whoosh'\n",
    "import os, os.path\n",
    "\n",
    "#from whoosh import index\n",
    "import whoosh\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "from whoosh.writing import AsyncWriter\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "\n",
    "class Indexer:\n",
    "    '''This class is used to create index of the WP database'''\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "      \n",
    "    ## Count documents\n",
    "    def countDocuments(self):\n",
    "        print(\"Counting documents, this might take a while...\")\n",
    "        counter = 0\n",
    "        tenKCounter = 0\n",
    "\n",
    "        with jsonlines.open(self.data_path) as reader:\n",
    "            for obj in tqdm(reader.iter(type=dict, skip_invalid=True)):\n",
    "                tenKCounter += 1\n",
    "                counter += 1\n",
    "            \n",
    "                if tenKCounter >= 10000:\n",
    "                    print(\"Current count is: \" + str(counter))\n",
    "                    tenKCounter = 0 \n",
    "        print(\"Last count is: \" + str(counter))\n",
    "        print(\"Counting done.\")\n",
    "    \n",
    "    def printDocumentData(self):\n",
    "        '''Prints every 10000th object'''\n",
    "        #dataframe = pd.DataFrame(columns = ['Title', 'Content', 'Year'])\n",
    "        with jsonlines.open(self.data_path) as reader:\n",
    "            counter = 0\n",
    "            for obj in tqdm(reader.iter(type=dict, skip_invalid=True)):\n",
    "                counter += 1\n",
    "                if (counter % 10000) == 0:\n",
    "                    print(\"Object number:\" + str(counter))\n",
    "                    print(type(obj))\n",
    "                    doc = Document(**obj)\n",
    "                    print(doc)\n",
    "                    \n",
    "    def createDocumentDataStore(self):\n",
    "        '''This method should read data and create the document data store'''\n",
    "        \n",
    "        with jsonlines.open(self.data_path) as reader:\n",
    "            #  PRODUCES MEMORY ERROR\n",
    "            #  PRODUCES MEMORY ERROR\n",
    "            id_doc_list = []\n",
    "            print(\"Start iteration\")\n",
    "            for obj in tqdm(reader.iter(type=dict, skip_invalid=True)):\n",
    "                document = Document(**obj)\n",
    "                id_doc_list.append({document.id, document})\n",
    "            \n",
    "            print(\"End iteration\")\n",
    "            print(\"Create store\")\n",
    "            dds = DocumentDataStore(id_doc_list)\n",
    "            print(\"Write file\")\n",
    "            outfile = open('docstore.pkl', 'wb')\n",
    "            pickle.dump(dds, outfile)\n",
    "            outfile.close()\n",
    "            print(\"Done\")\n",
    "        #  PRODUCES MEMORY ERROR\n",
    "        \n",
    "    def extractDocumentContents(self, contents):\n",
    "        '''Extracts document contents from array of dicts to string'''\n",
    "        #TODO IMPLEMENT\n",
    "        return \"\"\n",
    "    \n",
    "    def extractDocumentDate(self, epochTimestamp):\n",
    "        '''Converst UNIX epoch timestamp to DATETIME'''\n",
    "        if (epochTimestamp == ''):\n",
    "            return datetime(1,1,1)# TODO IMPLENT Error Handling: ValueError: invalid literal for int() with base 10: 'None'\n",
    "        \n",
    "        try:\n",
    "            date_info = epochTimestamp\n",
    "            removedZeros = str(date_info)[0:10]\n",
    "            timestamp = int(removedZeros)\n",
    "            return datetime.fromtimestamp(timestamp, timezone('EST'))\n",
    "        except:\n",
    "            print(\"ERROR: In extractDocumentDate()\")\n",
    "            print(\"ERROR: \", sys.exc_info()[0])\n",
    "            print(\"Caused by value: \" + str(date_info))\n",
    "            return datetime(1,1,1)\n",
    "        \n",
    "    \n",
    "    def index(self):\n",
    "        '''This method indexes the data'''\n",
    "        # https://whoosh.readthedocs.io/en/latest/api/writing.html\n",
    "        # https://appliedmachinelearning.blog/2018/07/31/developing-a-fast-indexing-and-full-text-search-engine-with-whoosh-a-pure-python-library/\n",
    "        \n",
    "        \n",
    "        #  [id, article_url, title, author, publised_date, contents, type, source]\n",
    "        # Define fields using whoosh's 'Schema' | https://whoosh.readthedocs.io/en/latest/schema.html#\n",
    "        # Can add field boost here\n",
    "        schema = Schema(doc_id = whoosh.fields.ID(unique=True),\\\n",
    "                       article_url = whoosh.fields.STORED,\\\n",
    "                       title = whoosh.fields.TEXT(stored=True),\\\n",
    "                       author = whoosh.fields.ID,\\\n",
    "                       published_date = whoosh.fields.DATETIME,\\\n",
    "                       contents = whoosh.fields.TEXT,\\\n",
    "                       type = whoosh.fields.STORED,\\\n",
    "                       source = whoosh.fields.STORED)\n",
    "        \n",
    "        # Create directory\n",
    "        if not os.path.exists(\"indexdir\"):\n",
    "            os.mkdir(\"indexdir\")\n",
    "        \n",
    "        # Creating a index writer to add document as per schema\n",
    "        myindex = whoosh.index.create_in(\"indexdir\",schema)\n",
    "        writer = whoosh.writing.AsyncWriter(myindex)\n",
    "        \n",
    "        # Loop over data\n",
    "        with jsonlines.open(self.data_path) as reader:\n",
    "            for obj in tqdm(reader.iter(type=dict, skip_invalid=True)):\n",
    "                writer.add_document(doc_id=obj['id'],\\\n",
    "                                   article_url=obj['article_url'],\\\n",
    "                                   title=obj['title'],\\\n",
    "                                   author=obj['author'],\\\n",
    "                                   published_date=self.extractDocumentDate(obj['published_date']),\\\n",
    "                                   contents = self.extractDocumentContents(obj['contents']),\\\n",
    "                                   type=obj['type'],\\\n",
    "                                   source=obj['source'])\n",
    "            writer.commit()\n",
    "        print(\"Index created!\")  \n",
    "        \n",
    "    \n",
    "\n",
    "data_path = 'WP-corpus/data/TREC_Washington_Post_collection.v2.jl'\n",
    "indexer = Indexer(data_path)\n",
    "#indexer.countDocuments()\n",
    "#indexer.printDocumentData()\n",
    "#indexer.createDocumentDataStore()\n",
    "indexer.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# import string\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# #nltk.download('stopwords')\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# # This function processes the user query\n",
    "# def query_representation_function(query):\n",
    "#     # Convert to lowercase\n",
    "#     query = query.lower()\n",
    "#     # Remove Punctuation ( !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ )\n",
    "#     query_removed_punctuation = \"\".join([char for char in query if char not in string.punctuation])\n",
    "#     # Tokenization\n",
    "#     query_tokenized = word_tokenize(query_removed_punctuation)\n",
    "#     # Stopword Filtering\n",
    "#     english_stopwords = stopwords.words('english')\n",
    "#     query_removed_stopwords = [word for word in query_tokenized if word not in english_stopwords]\n",
    "#     # Stemming\n",
    "#     porter = PorterStemmer()\n",
    "#     query_stemmed = [porter.stem(word) for word in query_removed_stopwords]\n",
    "    \n",
    "#     return query_stemmed\n",
    "\n",
    "# def test_print():\n",
    "#     test_query = \"This isn't a very long test query... I hope that I will be receiving a good answer! Give me results from the 2016 elections\"\n",
    "#     print(\"Test query:\\n\" + test_query)\n",
    "#     print(\"Processed query:\")\n",
    "#     print(query_representation_function(test_query))\n",
    "#     print(\"Test query after processing:\\n\" + test_query)\n",
    "\n",
    "# test_print()\n",
    "\n",
    "###############################################\n",
    "\n",
    "class Ranking:\n",
    "    '''This class is used to create a ranking'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Ranking class has been initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # scoring function\n",
    "# def get_score(row, query):\n",
    "#     score = 0\n",
    "#     for word in query:\n",
    "#         for col in ['Title', 'Genre', 'Description', 'Director', 'Actors', 'Year']:\n",
    "#             if word in str(row[col]):\n",
    "#                 # for now matching a keyword in any column counts the same (insufficient for now ofc)\n",
    "#                 score += 1    \n",
    "#     return score\n",
    "\n",
    "\n",
    "# def rank_movies(data, query):\n",
    "#     data['Score'] = 0\n",
    "#     for i, row in tqdm(data.iterrows()):\n",
    "#         score = get_score(row, query)\n",
    "#         data.at[i,'Score'] = score\n",
    "\n",
    "#     # first sort on Score then Rating\n",
    "#     data.sort_values(['Score', 'Rating'], ascending = False, inplace = True)\n",
    "    \n",
    "#     return data\n",
    "    \n",
    "# ranked_data = rank_movies(data, query)\n",
    "\n",
    "# display top 5 movies\n",
    "#ranked_data.head(5)\n",
    "\n",
    "################################################\n",
    "class Evaluation:\n",
    "    '''Used to evaluate the ranking results'''\n",
    "    #should check if query used is in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "\n",
    "##################################################\n",
    "class UserInteraction:\n",
    "    '''Class used to handle user interaction'''\n",
    "    shouldEvaluate = False\n",
    "    userQuery = \"\"\n",
    "      \n",
    "    def __init__(self):\n",
    "        '''This is the constructor method'''\n",
    "        print(\"UserInteraction class has been initiated.\")\n",
    "        # Retrieving query\n",
    "        self.userQuery = self.get_user_query()\n",
    "        print(\"Query entered: \" + self.userQuery)\n",
    "        \n",
    "        \n",
    "    def get_user_query(self):\n",
    "        ''''Retrieves the query from the user and returns it'''\n",
    "        userInput = input(\"Please enter a query: \")\n",
    "        return userInput\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block used to run everything:\n",
    "\n",
    "UI = UserInteraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
