{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RUN: 'pip install jsonlines' on: ModuleNotFoundError: No module named 'jsonlines'\n",
    "import json\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# RUN: 'pip install whoosh' on: ModuleNotFoundError: No module named 'whoosh'\n",
    "import os, os.path\n",
    "\n",
    "#from whoosh import index\n",
    "import whoosh\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "from whoosh.writing import AsyncWriter\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "######################################\n",
    "\n",
    "class Indexer:\n",
    "    '''This class is used to create index of the WP database'''\n",
    "    \n",
    "    index_created = False\n",
    "    index_directory = \"\"\n",
    "    data_path = \"\"\n",
    "    # [id, article_url, title, author, publised_date, contents, type, source]\n",
    "    # Define fields using whoosh's 'Schema' | https://whoosh.readthedocs.io/en/latest/schema.html#\n",
    "    # Can add field boost here\n",
    "    schema = Schema(doc_id = whoosh.fields.ID(unique=True, stored=True),\\\n",
    "                       article_url = whoosh.fields.STORED,\\\n",
    "                       title = whoosh.fields.TEXT(stored=True),\\\n",
    "                       author = whoosh.fields.ID,\\\n",
    "                       published_date = whoosh.fields.DATETIME,\\\n",
    "                       contents = whoosh.fields.TEXT)\n",
    "    \n",
    "    def __init__(self):\n",
    "        print('Indexer has been initiated.')\n",
    "        \n",
    "    def indexCreated(self):\n",
    "        return self.index_created\n",
    "      \n",
    "    ## Count documents\n",
    "    def countDocuments(self):\n",
    "        print(\"Counting documents, this might take a while...\")\n",
    "        counter = 0\n",
    "        tenKCounter = 0\n",
    "\n",
    "        with jsonlines.open(self.data_path) as reader:\n",
    "            for obj in tqdm(reader.iter(type=dict, skip_invalid=True)):\n",
    "                tenKCounter += 1\n",
    "                counter += 1\n",
    "            \n",
    "                if tenKCounter >= 10000:\n",
    "                    print(\"Current count is: \" + str(counter))\n",
    "                    tenKCounter = 0 \n",
    "        print(\"Last count is: \" + str(counter))\n",
    "        print(\"Counting done.\")\n",
    "        \n",
    "    def extractDocumentContents(self, contents):\n",
    "        '''Extracts document contents from array of dicts to string'''\n",
    "        build_string = \"\"\n",
    "        \n",
    "        for item in contents:\n",
    "            try:\n",
    "                if item['type'] == \"sanitized_html\":\n",
    "                    build_string = build_string + item['content']\n",
    "                    build_string = build_string + \"\\n\"\n",
    "            except:\n",
    "                build_string = \"Could not retreive content\"\n",
    "        \n",
    "        build_string = re.sub('<.*?>', '', build_string)\n",
    "        #print(build_string)\n",
    "        return build_string\n",
    "    \n",
    "    def extractDocumentDate(self, epochTimestamp):\n",
    "        '''Converst UNIX epoch timestamp to DATETIME'''\n",
    "        if (epochTimestamp == ''):\n",
    "            return datetime(1,1,1)\n",
    "        try:\n",
    "            # Test if source is within specified dates\n",
    "            date_info = epochTimestamp\n",
    "            removed_zeros = str(date_info)[0:10]\n",
    "            timestamp = int(removed_zeros)\n",
    "            return datetime.fromtimestamp(timestamp, timezone('EST'))\n",
    "        except:\n",
    "            print(\"ERROR: In extractDocumentDate()\")\n",
    "            print(\"ERROR: \", sys.exc_info()[0])\n",
    "            #print(\"Caused by value: \" + str(date_info))\n",
    "            return datetime(1,1,1)\n",
    "    \n",
    "    def setIndexDirectory(self, directory):\n",
    "        self.index_directory = directory\n",
    "    \n",
    "    def getIndexLocation(self):\n",
    "        return self.index_directory\n",
    "    \n",
    "    def setDataPath(self, file_location):\n",
    "        self.data_path = file_location\n",
    "    \n",
    "    def getDataPath(self):\n",
    "        return self.data_path\n",
    "    \n",
    "    def setIndexCreatedTrue(self):\n",
    "        self.index_created = True\n",
    "    \n",
    "    def getSchema(self):\n",
    "        return self.schema\n",
    "    \n",
    "    def index(self):\n",
    "        '''This method indexes the data'''\n",
    "        # https://whoosh.readthedocs.io/en/latest/api/writing.html\n",
    "        # https://appliedmachinelearning.blog/2018/07/31/developing-a-fast-indexing-and-full-text-search-engine-with-whoosh-a-pure-python-library/\n",
    "        \n",
    "        assert self.index_directory and self.data_path # Both variables have to be set\n",
    "        \n",
    "        schema = self.getSchema()\n",
    "              \n",
    "        # Creating a index writer to add document as per schema\n",
    "        myindex = whoosh.index.create_in(self.index_directory, schema)\n",
    "        writer = whoosh.writing.AsyncWriter(myindex)\n",
    "        \n",
    "        # Build full index? Or partial\n",
    "        full_index = True\n",
    "        \n",
    "        counter = 0\n",
    "        fault_counter = 0\n",
    "        true_scores = []\n",
    "        \n",
    "        if full_index:\n",
    "            checker = 10000\n",
    "        else:\n",
    "            checker = 100\n",
    "            \n",
    "            print(\"Downloading query results.\")\n",
    "            print(\"This might take a few seconds...\")\n",
    "            \n",
    "            # read in true scores file\n",
    "            true_scores_url = \"https://trec.nist.gov/data/core/qrels2018.txt\"\n",
    "            true_scores_file = urllib.request.urlopen(true_scores_url)\n",
    "\n",
    "            for line in true_scores_file:\n",
    "                decoded_line = line.decode(\"utf-8\")\n",
    "                decoded_line = decoded_line.split(\" \")\n",
    "                decoded_line = decoded_line[2]\n",
    "                true_scores.append(decoded_line)\n",
    "                \n",
    "            print(\"Done downloading query results.\")\n",
    "        \n",
    "        # Loop over data\n",
    "        print(\"Looping over data. Indexing each article.\")\n",
    "        print(\"This might take a few minutes...\")\n",
    "        \n",
    "        with jsonlines.open(self.data_path) as reader:\n",
    "            for obj in tqdm(reader.iter(type=dict, skip_invalid=True)):\n",
    "                index_line = False\n",
    "                \n",
    "                if not full_index:\n",
    "                    for line in true_scores:\n",
    "                        if line == obj['id']:\n",
    "                            true_scores.remove(line)\n",
    "                            index_line = True\n",
    "                else:\n",
    "                    index_line = True\n",
    "                    \n",
    "                if index_line:\n",
    "                    retreived_date = self.extractDocumentDate(obj['published_date'])\n",
    "                    \n",
    "                    if retreived_date == datetime(1,1,1):\n",
    "                        fault_counter = fault_counter + 1\n",
    "                        continue\n",
    "                        \n",
    "                    writer.add_document(doc_id=obj['id'],\\\n",
    "                                        article_url=obj['article_url'],\\\n",
    "                                        title=obj['title'],\\\n",
    "                                        author=obj['author'],\\\n",
    "                                        published_date=retreived_date,\\\n",
    "                                        contents = self.extractDocumentContents(obj['contents']))\n",
    "                    \n",
    "                    counter = counter + 1\n",
    "                    if counter > checker:\n",
    "                        writer.commit()\n",
    "                        writer = whoosh.writing.AsyncWriter(myindex)\n",
    "                        \n",
    "                        if full_index:\n",
    "                            checker = checker + 10000\n",
    "                        else:\n",
    "                            checker = checker + 100\n",
    "                        \n",
    "                        clear_output(wait=True)\n",
    "                        \n",
    "                        print(\"Looping over data. Indexing each article.\")\n",
    "                        print(\"This might take a few minutes...\")\n",
    "                        print(\"Indexed \" + str(counter - 1) + \" articles\")\n",
    "                        \n",
    "                        if fault_counter > 0:\n",
    "                            print(\"Found \" + str(fault_counter) + \" wrongly formatted articles\")\n",
    "            \n",
    "            print(\"Looping complete.\")\n",
    "        print(\"Index created!\")\n",
    "        self.setIndexCreatedTrue()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "from whoosh.qparser import QueryParser, MultifieldParser\n",
    "from whoosh import scoring\n",
    "from whoosh.index import open_dir\n",
    "\n",
    "class Ranking:\n",
    "    '''This class contains functions that are used to create a ranking based on different algorithms'''\n",
    "    \n",
    "    show_n_results = 3\n",
    "    index_directory = \"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Ranking class has been initiated.\")\n",
    "    \n",
    "    def indexCreated(self):\n",
    "        return indexCreated\n",
    "    \n",
    "    def setIndexDirectory(self, directory):\n",
    "        self.index_directory = directory\n",
    "    \n",
    "    def openIndex(self):\n",
    "        assert self.index_directory\n",
    "        return open_dir(self.index_directory)\n",
    "    \n",
    "   \n",
    "    def resultsToList(self, results):\n",
    "        results_list = []\n",
    "        for result in results:\n",
    "            result_dict = result.fields()\n",
    "            result_dict['score'] = result.score\n",
    "            results_list.append(result_dict)\n",
    "        return results_list\n",
    "            \n",
    "    \n",
    "    def searchWithSelectedAlgorithm(self, user_query, indexer, scoring_algorithm):\n",
    "    #TODO check if index has been created\n",
    "        index_dir = indexer.getIndexLocation()\n",
    "        self.setIndexDirectory(index_dir)\n",
    "        index = self.openIndex()\n",
    "        results_list = []\n",
    "        schema = indexer.getSchema()\n",
    "        fields = schema.scorable_names()\n",
    "        \n",
    "        with index.searcher(weighting=scoring_algorithm) as searcher:\n",
    "            #parsed_query = QueryParser(\"title\", index.schema).parse(user_query)\n",
    "            parsed_query = MultifieldParser(fields, schema).parse(user_query)\n",
    "            results = searcher.search(parsed_query, limit=self.show_n_results)\n",
    "            results_list = self.resultsToList(results)\n",
    "        \n",
    "        return results_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    def searchTermFrequency(self, user_query, indexer):\n",
    "        '''Returns results for a given query based on the TF-IDF search algorithm. Returned value is a list of dictionaries.'''\n",
    "        scoring_algorithm = scoring.Frequency\n",
    "        return self.searchWithSelectedAlgorithm(user_query, indexer, scoring_algorithm)\n",
    "            \n",
    "    \n",
    "    def searchTF_IDF(self, user_query, indexer):\n",
    "        '''Returns results for a given query based on the TF-IDF search algorithm. Returned value is a list of dictionaries.'''\n",
    "        scoring_algorithm = scoring.TF_IDF\n",
    "        return self.searchWithSelectedAlgorithm(user_query, indexer, scoring_algorithm)\n",
    "    \n",
    "    def searchBM25F():\n",
    "        '''Returns results for a given query based on the BM25F search algorithm. Returned value is a list of dictionaries.'''\n",
    "        scoring_algorithm = scoring.BM25F(B=0.75, content_B=1.0, K1=1.5)\n",
    "        return self.searchWithSelectedAlgorithm(user_query, indexer, scoring_algorithm)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def searchTermFrequencyReturnResults(self, user_query):\n",
    "    #TODO check if index has been created\n",
    "        index = self.openIndex()\n",
    "\n",
    "        with index.searcher(weighting=scoring.Frequency) as searcher:\n",
    "            parsed_query = QueryParser(\"title\", index.schema).parse(user_query)\n",
    "            results = searcher.search(parsed_query)            \n",
    "            return results\n",
    "\n",
    "    \n",
    "    def searchBM25FReturnResults(self, user_query):\n",
    "        index = self.openIndex()\n",
    "        with index.searcher(weighting=scoring.BM25F(B=0.75, content_B=1.0, K1=1.5)) as searcher:\n",
    "            parsed_query = QueryParser(\"title\", index.schema).parse(user_query)\n",
    "            results = searcher.search(parsed_query)            \n",
    "            return results  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking class has been initiated.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "import urllib\n",
    "\n",
    "class Evaluation:\n",
    "    '''Used to evaluate the ranking results'''\n",
    "    #should check if query used is in the \n",
    "    \n",
    "    # TODO load evaluation document and queries\n",
    "    # TODO pass queries on to ranking and obtain ranking results\n",
    "    # TODO compare ranking results to TREC evaluation\n",
    "    # TODO display results, how?\n",
    "    # TODO test different algorithms\n",
    "    \n",
    "    queries = []\n",
    "    ranking = Ranking()\n",
    "    \n",
    "    def load_queries(self):\n",
    "        \n",
    "        query_url = \"https://trec.nist.gov/data/core/topics2018.txt\"\n",
    "        query_file = urllib.request.urlopen(query_url)\n",
    "        titles, numbers = [], []\n",
    "        title = False\n",
    "        \n",
    "        for line in query_file:\n",
    "            decoded_line = line.decode(\"utf-8\")\n",
    "            \n",
    "            if title and not \"</title>\" in decoded_line:\n",
    "                titles.append(decoded_line.replace(\"\\n\", \"\").strip())\n",
    "\n",
    "            if \"<title>\" in decoded_line:\n",
    "                title = True\n",
    "            \n",
    "            if \"</title>\" in decoded_line:\n",
    "                title = False\n",
    "                \n",
    "            if \"<num>\" in decoded_line:\n",
    "                num = decoded_line.replace(\"<num>\", \"\").replace(\"</num>\", \"\").replace(\"\\n\", \"\").replace(\"Number: \", \"\").strip()\n",
    "                numbers.append(num)\n",
    "        \n",
    "        queries = list(zip(titles, numbers))\n",
    "        return queries \n",
    "\n",
    "        \n",
    "    def addResults(self, results_formatted, results, query, number):\n",
    "        count = 0\n",
    "        for hit in results:\n",
    "            current_result = str(number) + \" 0 \"                    \n",
    "            current_result = str(current_result) + str(hit.docnum) + \" \" + str(hit.score)           \n",
    "            results_formatted.append(current_result)\n",
    "            count += 1\n",
    "        print(\"for query {} there are {} hits\".format(query, count))\n",
    "        return results_formatted\n",
    "        \n",
    "        \n",
    "    def writeResults(self, results):\n",
    "        \n",
    "        with open(\"results.txt\", \"w\") as results_file:\n",
    "            for result in results:\n",
    "                results_file.write(result + \"\\n\")\n",
    "                \n",
    "    \n",
    "    def compareResults(self):        \n",
    "        # read in results.txt\n",
    "        predictions = []\n",
    "        with open(\"results.txt\", \"r\") as results_file:\n",
    "            for line in results_file:\n",
    "                current_result = line.split(\" \")\n",
    "                current_result = [i.strip(\"\\n\") for i in current_result]\n",
    "                \n",
    "                predictions.append(current_result)\n",
    "                \n",
    "        # read in true scores file\n",
    "        true_scores = []\n",
    "        true_scores_url = \"https://trec.nist.gov/data/core/qrels2018.txt\"\n",
    "        true_scores_file = urllib.request.urlopen(true_scores_url)\n",
    "\n",
    "        for line in true_scores_file:\n",
    "            decoded_line = line.decode(\"utf-8\")\n",
    "            decoded_line = decoded_line.split(\" \")\n",
    "            decoded_line = [i.strip(\"\\n\") for i in decoded_line]\n",
    "            \n",
    "            true_scores.append(decoded_line)\n",
    "        \n",
    "        \n",
    "        # compare results.txt (preds) with true scores\n",
    "        correct_preds, incorrect_preds = 0, 0\n",
    "        \n",
    "        for pred in predictions:\n",
    "            for true_score in true_scores:\n",
    "                \n",
    "                if pred[0] == true_score[0] and pred[2] == true_score[2]:\n",
    "                    if pred[3] == true_score[3]:\n",
    "                        correct_preds += 1\n",
    "                    else:\n",
    "                        incorrect_preds += 1\n",
    "                        \n",
    "                    break\n",
    "                    \n",
    "        if correct_preds == incorrect_preds == 0:\n",
    "            print(\"No matches found, because doc id's do not yet work\")\n",
    "\n",
    "        else:\n",
    "            print(\"Performance: {:.2f}%\".format(correct_preds/(correct_preds+incorrect_preds)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "class UserInterface:\n",
    "    '''Class used to handle user interaction'''\n",
    "          \n",
    "    def __init__(self):\n",
    "        '''This is the constructor method of the UI'''\n",
    "        print(\"UserInterface has been initiated.\")       \n",
    "        \n",
    "    def getUserQuery(self):\n",
    "        ''''Retrieves the query from the user and returns it'''\n",
    "        userInput = input(\"Please enter a query: \")\n",
    "        return userInput\n",
    "    \n",
    "    def indexAlreadyCreated(self, directory_location):\n",
    "        print(\"Index is set.\")\n",
    "        print(\"Index files are stored in directory:\" + directory_location)\n",
    "        return\n",
    "    \n",
    "    def shouldCreateIndex(self):\n",
    "        print(\"Do you wish to create a new index?\")\n",
    "        userInput = input(\"Answer [y/n]: \")\n",
    "        if userInput == ('y' or 'Y' or \"yes\"):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def indexIsNotSet(self):\n",
    "        print(\"Index has not been set.\")\n",
    "        return\n",
    "    \n",
    "    def getIndexDirectory(self, default_directory):\n",
    "        userInput = input(\"Please enter a directory name for the index (default = /\"+ default_directory + \"): \")\n",
    "        if userInput == \"\":\n",
    "            return default_directory\n",
    "        return userInput\n",
    "    \n",
    "    def getDataPath(self, default_data_path):\n",
    "        print(\"Please enter the path to the TREC_Washington_Post_collection.v2.jl file.\")\n",
    "        print(\"The default location is: /\"+ default_data_path + \"): \")\n",
    "        userInput = input()\n",
    "        if userInput == \"\":\n",
    "            return default_data_path\n",
    "        return userInput\n",
    "    \n",
    "    def creatingIndex(self, index_directory, data_path):\n",
    "        print(\"Creating Index.\")\n",
    "        print(\"Selected index directory:\\t\" + index_directory)\n",
    "        print(\"Selected file to index:\\t\" + data_path)\n",
    "        \n",
    "    def openingIndex(self, index_directory):\n",
    "        print(\"Opening Index.\")\n",
    "        print(\"Selected index directory to use:\\t\" + index_directory)\n",
    "    \n",
    "    def shouldAddExistingIndex(self):\n",
    "        print(\"Do you wish to add an existing index?\")\n",
    "        userInput = input(\"Answer [y/n]: \")\n",
    "        if userInput == ('y' or 'Y' or \"yes\"):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def stopSearchEngine(self):\n",
    "        print(\"Search Engine is stopped.\")\n",
    "        \n",
    "    def shouldTerminateSearchEngine(self):\n",
    "        print(\"Do you wish to stop the search engine?\")\n",
    "        userInput = input(\"Answer [y/n]: \")\n",
    "        if userInput == ('y' or 'Y' or \"yes\"):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def printResults(self, results):\n",
    "        if len(results) > 0:\n",
    "            print(\"\\nPrinting results:\")\n",
    "            counter = 1\n",
    "            for result in results:\n",
    "                print(\"Result \" + str(counter) + \":\")\n",
    "                print(result)\n",
    "                print(\"\")\n",
    "                counter += 1\n",
    "            return\n",
    "        print(\"No results found\")\n",
    "        return\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class SearchEngine:\n",
    "    '''This class embodies the search engine and acts a a controller class'''\n",
    "    \n",
    "    UI = None\n",
    "    Indexer = None\n",
    "    Ranking = None\n",
    "    \n",
    "    RUNNING = False\n",
    "    STOPPED = False\n",
    "    EVALUATION_MODE = False\n",
    "    USER_MODE = True\n",
    "    \n",
    "    user_query = \"\"\n",
    "    DEFAULT_data_path = 'WP-corpus/data/TREC_Washington_Post_collection.v2.jl'\n",
    "    DEFAULT_index_directory = \"indexdir\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Search Engine has been initiated.\")\n",
    "    \n",
    "    def stopSearchEngine(self, UI):\n",
    "        self.RUNNING = False\n",
    "        UI.stopSearchEngine()        \n",
    "        \n",
    "    def setIndex(self, Indexer, UI):\n",
    "        if Indexer.indexCreated():\n",
    "            directory_location = Indexer.getIndexLocation()\n",
    "            UI.indexAlreadyCreated(directory_location)\n",
    "            return\n",
    "        else:\n",
    "            UI.indexIsNotSet()\n",
    "            if UI.shouldCreateIndex(): # This is for creating a new index\n",
    "                # Index directory (setDir)\n",
    "                index_directory = UI.getIndexDirectory(self.DEFAULT_index_directory)\n",
    "                Indexer.setIndexDirectory(index_directory)\n",
    "                # Check if index_dir exist and makes one if it doesn't\n",
    "                if not os.path.exists(index_directory):\n",
    "                    os.mkdir(index_directory)\n",
    "                \n",
    "                # Data file path (setPath)    \n",
    "                data_path = UI.getDataPath(self.DEFAULT_data_path)\n",
    "                Indexer.setDataPath(data_path)\n",
    "                \n",
    "                # Creating Index\n",
    "                UI.creatingIndex(index_directory, data_path)\n",
    "                Indexer.index()\n",
    "                return\n",
    "                \n",
    "            elif UI.shouldAddExistingIndex(): # This is for adding an existing index\n",
    "                \n",
    "                # TODO add checks to check for existence of index?\n",
    "                \n",
    "                # Index directory, duplicate code -> (setDir)\n",
    "                index_directory = UI.getIndexDirectory(self.DEFAULT_index_directory)\n",
    "                Indexer.setIndexDirectory(index_directory)\n",
    "                # Check if index_dir exist and makes one if it doesn't\n",
    "                if not os.path.exists(index_directory):\n",
    "                    os.mkdir(index_directory)\n",
    "                \n",
    "                # Data file path, duplicate code -> (setPath)    \n",
    "                data_path = UI.getDataPath(self.DEFAULT_data_path)\n",
    "                Indexer.setDataPath(data_path)\n",
    "                \n",
    "                # Set index created to true\n",
    "                UI.openingIndex(index_directory)\n",
    "                Indexer.setIndexCreatedTrue()\n",
    "                return\n",
    "                                \n",
    "            else: # TODO: Ask if the user wants to continue or stop\n",
    "                if UI.shouldTerminateSearchEngine(): \n",
    "                    self.STOPPED = True\n",
    "                return\n",
    "            return\n",
    "       \n",
    "    def run(self):\n",
    "        '''This function start the search engine'''\n",
    "        print('Search Engine started.')\n",
    "        \n",
    "        self.UI = UserInterface()\n",
    "        self.Indexer = Indexer()\n",
    "        self.Ranking = Ranking()\n",
    "                \n",
    "        self.RUNNING = True\n",
    "        while self.RUNNING:\n",
    "            if not self.Indexer.indexCreated():\n",
    "                #TODO Inform user that an index needs to be set\n",
    "                self.setIndex(self.Indexer, self.UI)\n",
    "                if self.STOPPED == True: # Stop SE if user did not want to continue\n",
    "                    self.stopSearchEngine(self.UI)\n",
    "                    break\n",
    "            #TODO ask user to choose a mode\n",
    "                       \n",
    "            if self.EVALUATION_MODE:\n",
    "            # This is used to evaluate SE against the TREC relevance judgements\n",
    "                index_dir = self.Indexer.getIndexLocation()\n",
    "                self.Ranking.setIndexDirectory(index_dir)\n",
    "                \n",
    "                evaluation = Evaluation()\n",
    "                queries  = evaluation.load_queries()\n",
    "                print(\"Queries loaded\")\n",
    "                \n",
    "                results_formatted = []\n",
    "                \n",
    "                for (query, number) in tqdm(queries):\n",
    "                    #results = self.Ranking.searchTermFrequencyReturnResults(query)\n",
    "                    results = self.Ranking.searchBM25FReturnResults(query)\n",
    "                    results_formatted = evaluation.addResults(results_formatted, results, query, number)\n",
    "                \n",
    "                evaluation.writeResults(results_formatted)\n",
    "                evaluation.compareResults()    \n",
    "                \n",
    "                print(\"Done\")\n",
    "                self.RUNNING = False\n",
    " \n",
    "            if self.USER_MODE:\n",
    "                # This is used to query questions\n",
    "                #TODO ask for search algorithm\n",
    "                #TODO ask for user query\n",
    "                #TODO move printing results to UI\n",
    "                print(\"Entering USER_MODE\")\n",
    "                user_query = self.UI.getUserQuery()\n",
    "                print(\"Entered query: \" + user_query)\n",
    "                \n",
    "                results = self.Ranking.searchTermFrequency(user_query, self.Indexer)\n",
    "                self.UI.printResults(results)\n",
    "                \n",
    "            print(\"Starting over.\")\n",
    "            print(\"------------------------------------------------------------------------\")\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mySearchEngine = SearchEngine()\n",
    "mySearchEngine.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
